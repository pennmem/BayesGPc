11/23/21

decide on set of initial tests and metrics for tuning algorithm and for achieving an endpoint
get better notetaking system in place
get tests running on Rhino
logging (use Elemem logger)
    make full logger and logger with just test results, 
    put arguments on top of both and/or , 
    make separate directory for each test, standard file structure inside
    put main arguments in directory name, others put in files and in arg config file
add warm starts
add intelligent choices of initializations for kernel HP tuning process
clean up getNextSample(), remove use of "new" if possible (I couldn't tell James why I did this, but I think
    I remember something in CGp failing when I tried that more direct approach)
implement one-sample update function, test runtime

need to deal with degenerate fitting scenarios, either select kernel HP ranges that won't result in trivial values
    (maybe a bad idea?), take best estimate (one with highest "reasonable" max) over final five sample updates, or
    perturb the samples with noise to try to shake out of degenerate local optima
    seems like algorithm either grabs onto an optimum early and converges to a non-trivial HP set or else just finds a degenerate HP set and randomly samples everywhere

get standard run scripts in place for running core experiments with all functions (with appropriate numbers of runs)
    all noise levels of interest, all main hyperparameter settings

find another implementation to compare performance against
    also compare against L-BFGS without bounding, which seemed potentially qualitatively different, 
        could handle errors differently if needed

    add metrics of sample density/entropy, seems like current Bayesian search scheme fixates too early
        might have issues with current best being driven by noise? might want to look into Ax scheme for handling this,
        although it used Monte Carlo sampling which we likely can't rely on for computational reasons
    
    tune the kernel hyperparameters with a standard script

    get two more standard optimization benchmark functions

    check what sciopt implementation is doing, might be suboptimal

    add uniform random sampling search process on top of GP for comparison
    get standard implementation of Bayesian search
    try differential evolution and other global optimization algorithms that handle noisy observations

confirm whether "new sample" should be "new sample" or actually "next sample" 


finish testing/debugging
get VS Code Git integration in place
Windows build, check in with Ryan about Windows 10 compatibility
clean up deletion and recreation of models upon sampling new points
test 1-sample update to Cholesky decomposition
    will only work if hyperparameters are fixed between updates... may be okay, particularly once many samples are collected,
    can also retune periodically and definitely at the very end for the selection of discrete locations
implement discrete variable/location selection scheme, talk to Mike about it, look at other papers
integration with Elemem
Latin hypercube sampling, orthogonal sampling
    could just use Bayesian search with observation values set to zero on top of a 
    small initial set of random samples (like 3 samples) or else with some small random sampling perturbation
    then sampling would be biased toward regions with low sample density, producing uniform samples with less
    clustering of samples

update slides for meeting with Dan

got L-BFGS-B in place, testing
random testBayesianSearch processes running in background, don't seem like additional processes?


Installation notes:

Mac build requires Xcode version 12.05 (newer versions broke the build)

look into version packaging for reproducibility

cnpy (for loading ndarrays from Python), could replace with h5
    Linux, Mac: install from source
    git clone git@github.com:rogersce/cnpy.git
    follow installation instructions on github repo page
    cd path/to/cnpy
    cmake .
    make 
    make install

boost (could be removed if we wanted, just using distribution libraries for now)
    Mac:
    brew

    Linux:
    just use headers

matplotplusplus (for plotting test results)
    git clone git@github.com:alandefreitas/matplotplusplus.git

    Linux:
    install from source via cmake

    $ mkdir build
    $ cd build
    $ cmake .. -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS="-O2"
    $ sudo cmake --build . --parallel 2 --config Release
    
    To use x11 for graphic output, may need to run 
    $ set term x11
    before plotting with gnuplot (matplot uses gnuplot)
    can test gnuplot with
    $ gnuplot
    > plot x,sin(x)
    should open a window with sin(x) plot
    
    install cimg-dev, needed dependencies, in particular libtiff-dev
    include matplot.h in source code and gcc command
    link to the static libraries libmatplot.a and nodesoup.a in (separate subdirectories of) the build directory
    link to the dependencies -lm -lpthread -lX11 -ltiff -ljpeg -lpng -lz
    
    Mac:
    install via homebrew

gfortran:
    Mac:
    must use gfortran-7, install downgraded version of gcc

    Linux Ubuntu (WSL2):
    gcc 9.3.0 worked

eigen (matrix algebra library; dependency of optim)
    change line 107 in optim/include/misc/optim_options.hpp to
        #include <[your eigen header library location here, should start with eigen[version number here] in e.g. /usr/local/include]/Eigen/Dense>
    use header-only library, might consider finding way of using BLAS/OpenBLAS
    without intefering with access of BLAS/LAPACK by CGp by pre-compiling for additional performance boost

optim
    git clone git@github.com:kthohr/optim.git
    change line 
    change line 99 of optim/src/unconstrained/de.cpp to 
        X_next.row(i) = OPTIM_MATOPS_TRANSPOSE( par_initial_lb + OPTIM_MATOPS_HADAMARD_PROD( par_initial_ub - par_iniial_lb, OPTIM_MATOPS_RANDU_VEC(n_vals) ) );
        (obvious bug fix, pull request not made yet)
    ./configure --head-only-version


11/11/21

TODO
  // TODO test acquisition functions in separate file
  // TODO separate out acquisition functions with templates, virtual function implementation
  exception handling. if GP or global optimizations fail, need to just sample uniform sample with 
  logged error message
    matrix non positive definite error obtained after (10) initial samples collected
        there might be an infinite loop in the Cholesky decomposition jittering?
        in schwefel x_dim=3,4 hanging runs, matern32 length scale stuck at 1 and variance stuck (in both models) at 
            0.81832 over multiple samples
        schwefel x_dim=2 also hanging, but not on first run (completes 6 runs with decent success) 
        and doesn't have similarly "stuck" parameters on hanging run
        possible that hanging runs occur for poor condition numbers
            check to what extent they drive longer compute times
                can't find anything on this

        CURRENTLY NOT ASSIGNING OPTIMAL PARAMETERS WITH LBFGS WITH IFLAG = 0?

        what would lead to non-PD matrices, which hartmann4d (which has standardized input range) run finally led to?
            numerical error
                exacerbated by small parameter values leading to small kernel matrices?
                jitter attempts failed in hartmann4d
                    max diagonal value added is multiple of trace, in one case with hartmann4d, was 4e10
                    parameters explode on some parameter optimization runs, leads to large kernel values
                    final exploded log parameters are huge, lead to incorrect linear param values >> linear params limited internally
                    seems like we need a different optimization algorithm with bounds
                    try sklearn's FORTRAN routine instead, has bounds built in
                    seems like these issues could result with poor noise samples leading to loss surfaces where 
                    divergent parameters trivially improve loss
                    could regularize rather than use bounds? could just apply L2 to kernel variances with low weight?
                        don't really want spherical regularization, although it would prevent the observed imbalance in 
                        variances between the white kernel and the non-trivial kernel
            logical errors
            optimization sometimes explodes

        check error messages, see which matrices are breaking down
            potrf, jitter tries failed, non-PD
                with sin and quadratic funcs, kernel HPs not vanishing, 
                hartmann4d matern variance vanishing, white kernel var not vanishing
                    hartmann4d fails on first run with noise level = 0.3, maybe noise worsens issues
            symmetry error = 0 in hartmann4d

            potri also returns non-PD matrix error later, potentially implying that potrf succeeded and then potri failed
            additional LFBGS errors in MCSTEP search found, none sounds fatal, just numerical stuff
        also try different kernels in CGp, might be issue with matern32 specifically
            unlikely, but should still try
        check if I'm directly assigning CMatrix vals arrays assuming row-major order while they actually have column-major order
        error in relative error calculation, some cases observed (in deleted file) where max found = 1.4, BO opt = <~1.4 and
            rel err = -12

                check covariance matrices, other matrices that are being Cholesky decomposed
            which matrices are being decomposed specifically?
            check values of matrices, might be the case that matrices are collapsing when matern32 length scale/variance
            grows too small, which happened in some of the cases but not all
            check that symmetry is being asserted
                is being asserted, but not numerically checked, now being numerically checked
            check condition numbers
                different condition numbers, not sure at this point
        try increasing alpha/CNoise model values to improve conditioning numbers? try forcefully preventing non-PD errors
        can also try fixing a minimum value for the main kernel variances
        check whether test functions are non-isometric, i.e., whether the intrinsic length scale varies directionally
        check where exactly CNoise values came into play
        get 2D plotting in place
        try standardizing schwefel x domain? hartmann4d is standardized, also hangs
        
        handle every GPc ndl/optim error dependent on matrices being e.g. PD, nicely behaved, everything that can go wrong stochastically, 
            likely with a random sample
        catch every other error with a random sample

        
        DONE increase computational resources devoted to global search for higher dimensional functions
        DONE confirm sklearn comparison tests are still similarly passing and that I didn't break something
            kernel tests passing
            GPR tests passing to same degree they were before as far as I can remember (some failures, but still optimizing, seems more like some kind of disalignment of values)
        DONE try to get these failures to occur for 1D test functions
            broke for schwefel 1D... never happened before...
            quadratic also just failed after ~65 runs, no error message, just exited, later failed with error message
        DONE try to reproduce these failures in the debugger? tricky, can't break into catch statements, could set conditional 
        breakpoints
            seeding appears to produce reproducibility as of 11/26/21
  
  // TODO test optimization of acquisition function


unit tests, performance tests, runtime tests
    performance functions
        mixture of N gaussians test with random multidimensional mean 
            locations so long as means are decently distributed
        simple linear functions
        DONE negative QUADRATIC with peak at edge
            tests whether DE has bias against testing edges with log-transforms
            GP/acquisition function seems to find/latch onto edge very quickly
                might be due to high SNR, but ultimately, we don't want to cling to edges
                might want to add noise to sampled values to prevent resampling edges
                std estimate doesn't seem to shrink much from additional samples, likely because of high noise
                could try lower noise levels as well
            some sporadic fits are completely off from sampled points
                strangely, the likelihood was not shot
                FIXED bias may not have been learned properly
        DONE negative quadratic with peak before edge
            tests case in which delta increases monotonically with amplitude
        functions with varying length scales
        DONE function dependent on ||x||, e.g., sin(||x||), to test for feature independent effects
            most of these kernels are stationary, so these effects should be captured
        schwefel test function
            has both of the previous properties
            x_dim 1: passing at noise level of 0.1
            x_dim 2: failing everything, finding exact same local minimum over and over, matern32 variance collapsing to zero
            x_dim 3: not completely failing, but not optimal either
            x_dim 4: failing, along with hartmann4d
            all initial samples for test functions with even number of dimensions are along edges of input space
            
            FIXED model currently failing to find correct lengthscales and biases
                length scale seem fixed to upper bound of 1
                lengthscale is not arbitrarily fixed to upper bound of 1. with function 'sin', 
                length scale grows above 1
        PS4_2 (multi-modal PS4 test)
            DE failing to find global optimum, tests are artificially passing


find solid unit testing framework, look into what Elemem
is using
add observation noise to predictions
    try reducing observation noise, better to only allow
    model to fit to data? don't want higher noise than
    needed

need to correct gradients in CGp for noise, failing CGp grad tests only with observation noise and matern32 kernel, 
passing them without observation noise
try multiple L-BFGS optimization runs, other solvers

implement discrete location selection


11/9/21

Select kernel with CV once we have data
in what way are the collected samples biased by the search produced by the selected kernel?

How is prior variance selected? Just observation noise?

Extensions:
prior sample weighting/weighted GP - simple technique
how to determine the weights?
if you had multiple prior subjects, you could directly compute this with leave-one-patient-out cross validation
on the log-likelihood, i.e., fit on all subjects' data but one and all of that one
patient's data but one session. Tune the weight on performance (marginal likelihood, MSE...)
this would give an optimized weight for each subject tuned for generalization performance,
could take mean or probably better, median

could look at distribution of kernel HPs across subjects, maybe just reuse HPs from previous subjects
might think that different subjects would have similar HPs, but task, classifiers, electrodes, patients, etc.
are very noisy...

could anneal prior data weighting over the course of training

question of generalization:
tuning HPs on marginal log-likelihood alone for all current data could overfit, can overfit to noise
since we're just using GP as a proxy for search, we don't necessarily care as much during search
poor generalization during search would be expected to decrease sample efficiency (which we don't want, but
wouldn't be fatal) but adding noise to the search isn't terrible given the model assumptions aren't entirely 
correct.
Weighting initial samples with prior data would provide for regularization.
Increasing the sample noise estimate would as well.
We could penalize the log likelihood in other ways as well
>> it'd really be nice to have an autograd system in place >> could consider pytorch/tensorflow c++...


We want a robust method for comparing effects of stim. after fitting
CV via fitting HPs on different subsets of subject data? how to aggregate model predictions across folds
to obtain prediction of best set of parameters?



use non-behavioral data to estimate effects on classifier features, then use mean feature weights in each 
region to estimate delta variance
start out looking at feature variances rather than classifier weights

look at all data sets with BlackRock systems and 500 ms stim length
non-behavioral data sets: ps1, 2, 2b, 3, 4 data sites - 150 patients, subjects have to sit and do little
behavioral datasets: FR3 catFR3, PAL3 - 50 patients
    stim occurs at particular points in time during a task with a particular structure
    get an effect of not only stim but also current brain activity/behavior > behavior adds noise
    but behavioral task allows for directly measuring what we care about

Mike would start with OPS data, has larger data set per patient, get pipeline working, then expand to other
data sets
OPS is most recent, if there are issues I can talk to Ryan who wrote the code, OPS is smaller though

eventually, look at aggregate classifier across subjects/regions
John Burke's univariate analyses didn't take into account feature correlations, this would allow for 
feature correlations and be on a much larger dataset (450 subjects vs. 90)




variable length scales over domain

multidimensional:
    anisotropic kernels/length scales

    discrete models (might be better to just implement a bandit model to choose sampling for a set of GPs than
        to directly use a GP with discrete RVs in combination with continuous RVs)


Testing
push
Start with unit tests rather than qualitative testing, unless I have specific hypotheses in mind to improve fits
Add search performance tests
Add timing tests
    ask James and Ryan about computational resources available at sites
smart pointers


11/8/21

BO is mostly working on 1D test function of sin(x) with Matern32 kernel based on qualitative plotting tests
0.3 noise level in samples, lower alpha value (0.05) was used for most experiments than in sklearn
using 0.45 (value used in sklearn), resulted in flat predicted variances and less exploration
no, CGP WAS NEVER IMPLEMENTING OBSERVATION NOISE...

DE is optimizing EI decently well, misses sporadically

overall exploration is more "reluctant", much higher exploration biases being used...

CGp GP fit is much rougher than fit with sklearn using same kernel

Seems like the predicted variance might be flatter than sklearn?
sklearn appears to be only adding observation noise to sample variances, whereas CGp is adding noise all 
elements of covariance
CGp was not adding observation noise to diagonal elements

Also had one instance where GP fit was drastically off after a new sample (curves fit to twice the true curves), 
will need to detect that... maybe just an outlier detection scheme on the log likelihood

EI returning constant values oftentimes?


Model definitely slows down considerably after 100 points, gets to about 2 Hz rate around 200 samples...
Probably will need sparse sampling, batched updates, some additional optimization/caching 
(fit HPs with only prior data from other patients), 
using better (parallelized) libraries
column-row addition update to Cholesky - Linpack - O(k^2)
averaging multiple samples together would reduce sample noise and computational costs
check if optim allows for batch sampling of the objective with population-based methods

full updates to Cholesky decomposition could be performed periodically to manage numerical error and
to remove e.g. samples from prior subjects below some weighting threshold during prior data annealing
