2/16/22

make minimal CBayesianSearch updates to test
    DONE out_sem
        needs debugging, getting negative resulting predictive variances...
        getting non-PSD matrices again
        errors seem to be driven by nans in covariance matrices
            nan covariance elements occur with identical x's
            however, nan does not always occur even when three x's have the same value
            occurs with Matern32, Matern52, not with RBF, RationalQuadratic
                (RBF and RatQuad seem to obtain lower performance than Matern 32 on most test functions with low to medium relative errors?)
                RBF had incorrect specification of inverse width bounds
            non-PSD errors with nans occurring on Mac and rhino

            errors with non-negative predictive variance far more common for noise_level = 0.0, white noise collapses to min bound, should probably raise for numerical stability
                but not always
                increased white noise min bound to deal with numerical instability with noise_level = 0
                    eliminated negative predictive var errs with RBF
                    seems along with error catching on all model fits to have 
                        potentially eliminated all errors with Matern32 as well?
                        warning message if error caught during fitting process not sent to console
                        Tried only 15 runs with noise_level=0 and 0.3, no errors, model seemed to be making estimates...
            
            TODO eliminate model deletion/construction before every samples
                then add parameter saving before try catch blocks so previous GP params 
                can be fallen back on instead of just random sampling
            TODO add random parameter fit restarts to COptimisable.cpp
            TODO figure out why nans were occurring, probably sqrt of negative num
            TODO clean up dependencies, ask Ryan and James what they're doing to link to other projects

        check with white noise included in uncertainty predictions? 
            don't think non-PSD error has anything to do with predictive variance computations
    DONE standard way to control search space bounds
    debug RNG seeding
    start tests
    make minimal analyses of results
CSearchComparison
    either fix out_sem if possible or implement degrees of freedom from Hastie et al.
    test
debug CBayesianSearch optimization errors (non-PSD)
    clean up CBayesianSearch with better updating of samples
Elemem integration
Elemem on Windows
find video
submit my Elemem code for review


2/8/22

Elemem integration

config:

test experiment

update BO or ExperCPS to handle multiple parallel searches
    solve issue with out_sem
    test

add discretized grid search functionality for selecting next point
    add search space constraints similar to skopt

LATER:
interface:
    add min/max check boxes for amplitude
        currently just assuming max ampitude is approved amplitude, min is 0
    add multidimensional length scales

1/28/22

-PS4 used 5 restarts in the GP tuning process, try this
    setting initial length scales to values other than the lower
    bound resulted in frequently tuning to upper bound for high 
    noise with skopt implementation. Strangely, though CBayes
    is using same optimizer and the HP bounds used are huge,
    this doesn't seem to be an issue with CBayes? 
    
    No, CBayes is frequently converging to small length scales on
    schwefel, 
    need to add named hp setting and hp bounds to all kernels

    Generally, all hp initializations are set to 1 in CBayes as well
    issues mostly resolved in skopt implementation with init 
    length scale of 1, optimization mostly just stuck on 
    lower bound then, probably trying to converge to zero 
    length scale/Matern variance but can't... 
    not really optimizing well, just working because schwefel has
    intrinsic length scale of ~0.1
    probably doesn't matter for smoother functions like what we expect
    for amplitude... this still works? 
    tunes Rosenbrock fine, kinda easy if goal isn't global optimum
    high noise conditions are hard...
    
-get Python tests started
    test across a few major kernels, both qualitatively and quantitatively
    just set hp ranges in reasonable range, then leave fixed
    try a few different values for the white noise parameters
    record hp values
-integrate into Elemem
    Elemem CPS task design and testing
    CMake dependencies
-update CBayesianSearch
    add named hp setters/bounds
    exclude white noise from predictive variance
    add random restarts to HP tuning?
    start these tests as well
    fix 2D plotting seg faults

-add robust exception handling
    HP restarts
-implement and test selection of different discrete locations
-add Latin hypercube sampling
-consider adding additional randomization to prevent selection of same
    points repetitively, can raise exp bias, need to carefully tune
-add other improvements to algorithm, see below, in particular warm starts
    and random selections if HP optimization taking too long with restarts
-check what PS4 did for discrete parameter space
    didn't seem to do anything special, may have been rounding to the nearest uA
    1 uA was the smallest increment they rounded to in the Python code, dug into the cpp
    implementation and didn't see anything else before the OdinLib DLL was called
    found bug with GP SEM computation for the location comparisons

-choose educational video
-choose lockout period
-separately log GP selected value and GP HPs at each iteration along
    with BlackRock-rounded stim parameters


Python reference implementation:
    tune Python kernel

tests:
    Ray-tracing function - Daniel Utin can send me the C++ code, they used swig to interface with Python
look into discrete RVs
look into standard optimization tuning methods, see previously found papers
    may want to compare performance directly with Picheny et al.

try setting min length scale to 0.05 * domain
    Picheny et al. did this, said it was common practice
test whether global optimization of acquisition function is finding true optimum by comparing with more intensive tuning process
add non-isotropic length scales - most of the test functions are either isotropic or smooth
    or at the very least, rescale domain
for selecting the next sample, consider treating observation noise as a separate component of variance from the uncertainty
    in the GP estimate of the mean, should increase exploration and reduce oversampling the current best point
    Sklearn implemented the observation noise as a constant and separate component of the variance, e.g., as constant white kernel
    other references (https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote15.html) did the same
    however GPML, Ch. 2 pg. 16 does not include the observation noise in the estimates of the conditional predictive covariance
    same with Picheny, V., Wagner, T., & Ginsbourger, D. (2012). A benchmark of kriging-based infill criteria for noisy optimization.
    seems like this is a modeling decision, no concensus
    TODO add measure of sample point entropy, should really just be able to measure if a run has locked on to a particular value

implement reference implementations
do stats in Python
    add sample entropy metric
        a little involved, see Paninski 2003
    add option to compute mean improvement in estimate per sample and std? probably too high variance/multi-modal depending on local minima/degeneracy in GP HP tuning

tune/debug algorithm
integrate into Elemem - talk with James and Ryan
get running on Windows - talk with Ryan

Misc.
    may have memory leak with current method of reinstantiating GPc model in BayesianSearchModel after adding each sample?
    2D plotting segfaulting unexpectedly... seems potentially related to 
    larger samples
    replace all inputs to testBayesianSearch with config json instance
    make test function members private
    fix seg fault when init_samples > n_iters (or when n_iters is small?)

speed up compilation time
    currently, compilation of testBayesionSearch.o takes ~30 s, linking of testBayesianSearch takes ~20 s
    if needed, add more granularity to the usage of the header files, try to compile them once in the needed files
    and nowhere else
    also look into using .a libraries to reduce compilation redundancy


notes from playing around with skopt on schwefel and rastrigin:
    restarts could be quite helpful for multimodal functions
    model often fixates on a single optima
        however, more exploration can be driven with far higher exp biases (1.0-5.0)
    results and final kernels hyperparameters from run to run are highly variable
        GP fits feel unstable. high noise conditions are challenging...
    qualitative behaviors:
        best fit converging on pure noise, often results in argmin nowhere near an
        optima, GP estimates optima in clearly suboptimal places, values that are not
        even local optima, often just outside and hanging over into local optima
    seems like searching with predictive mean variance rather than sample variance
    could help encourage more
    exploration with greater difference between explored and unexplored regions,
    will make large difference in exp bias values between skopt/CBayes implementations
    even successful runs that converge on a decent local optima often don't find
    the bottom of that optima, likely means more exploration bias needed
        

add warm starts
add intelligent choices of initializations for kernel HP tuning process
consider removing white noise variance for estimating predictive variance of the mean?
    GPML did not add noise variance to predictive variance, 
    but white kernel, which represents the noise level (and is learnable), 
    does just this. Current observation noise is only added to observation kernel covar,
    but white kernel noise is still present in predictive kernel, givng a result
    that is unprincipled (only part of the estimated observation noise is included)
    Better approach would be to place min noise level on white kernel,
    thereby replacing the current function of the observation noise as a min noise level,
    then I should remove the white kernel noise from the predictive variance to obtain
    an estimate of the variance of the predictive mean. 
    Would this variance (with the white kernel removed) be estimating the predictive
    variance in the mean? That is what we want use to compare models, not the predictive
    variance of individual samples at a location
    
    If the mean at a point is known, then the variance of a sample at that point will 
    be the observation noise by definition. If the mean is unknown, then the predictive 
    sample variance will be the observation noise plus the predictive mean estimation noise?
    The observation noise is assumed to be additive and independent of the mean. 
    Therefore, it may be subtracted from the total variance to obtain the mean estimation 
    variance since there are no other sources of variance beyond the uncertainty in 
    estimating the mean and the observation noise (we assume the covariance is fixed by
    construction and is independent of the sample values themselves but could have
    its uncertainty modeled as well?)
any needed adjustments for sampling at only highly discrete points?

clean up getNextSample(), remove use of "new" if possible (I couldn't tell James why I did this, but I think
    I remember something in CGp failing when I tried that more direct approach)
implement one-sample update function, test runtime
try adding option for restarting search, then combining all samples over various restarts for decorrelated searches (also faster runtimes)

need to deal with degenerate fitting scenarios, either select kernel HP ranges that won't result in trivial values
    (maybe a bad idea?), take best estimate (one with highest "reasonable" max) over final five sample updates, or
    perturb the samples with noise to try to shake out of degenerate local optima
    seems like algorithm either grabs onto an optimum early and converges to a non-trivial HP set or else just finds a degenerate HP set and randomly samples everywhere

find another implementation to compare performance against
    also compare against L-BFGS without bounding, which seemed potentially qualitatively different, 
        could handle errors differently if needed

    add metrics of sample density/entropy, seems like current Bayesian search scheme fixates too early
        might have issues with current best being driven by noise? might want to look into Ax scheme for handling this,
        although it used Monte Carlo sampling which we likely can't rely on for computational reasons
    
    tune the kernel hyperparameters with a standard script

    add uniform random sampling search process on top of GP for comparison
    get standard implementation of Bayesian search
    try differential evolution and other global optimization algorithms that handle noisy observations

get VS Code Git integration in place
Windows build, check in with Ryan about Windows 10 compatibility
clean up deletion and recreation of models upon sampling new points
test 1-sample update to Cholesky decomposition
    will only work if hyperparameters are fixed between updates... may be okay, particularly once many samples are collected,
    can also retune periodically and definitely at the very end for the selection of discrete locations
implement discrete variable/location selection scheme, talk to Mike about it, look at other papers
integration with Elemem
Latin hypercube sampling, orthogonal sampling
    could just use Bayesian search with observation values set to zero on top of a 
    small initial set of random samples (like 3 samples) or else with some small random sampling perturbation
    then sampling would be biased toward regions with low sample density, producing uniform samples with less
    clustering of samples

got L-BFGS-B in place, testing
random testBayesianSearch processes running in background, don't seem like additional processes?


Installation notes:

Mac build requires Xcode/clang version 12.0.5 (newer versions broke the build)

look into version packaging for reproducibility

cnpy (for loading ndarrays from Python), could replace with h5
    Linux, Mac: install from source
    git clone git@github.com:rogersce/cnpy.git
    follow installation instructions on github repo page
    cd path/to/cnpy
    cmake .
    make 
    make install

boost (could be removed if we wanted, just using distribution libraries for now)
    Mac:
    brew

    Linux:
    just use headers

matplotplusplus (for plotting test results)
    git clone git@github.com:alandefreitas/matplotplusplus.git

    Linux:
    install from source via cmake

    $ mkdir build
    $ cd build
    $ cmake .. -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS="-O2"
    $ sudo cmake --build . --parallel 2 --config Release
    
    To use x11 for graphic output, may need to run 
    $ set term x11
    before plotting with gnuplot (matplot uses gnuplot)
    can test gnuplot with
    $ gnuplot
    > plot x,sin(x)
    should open a window with sin(x) plot
    
    install cimg-dev, needed dependencies, in particular libtiff-dev
    include matplot.h in source code and gcc command
    link to the static libraries libmatplot.a and nodesoup.a in (separate subdirectories of) the build directory
    link to the dependencies -lm -lpthread -lX11 -ltiff -ljpeg -lpng -lz
    
    Mac:
    install via homebrew

gfortran:
    Mac:
    must use gfortran-7, install downgraded version of gcc

    Linux Ubuntu (WSL2):
    gcc 9.3.0 worked

eigen (matrix algebra library; dependency of optim)
    change line 107 in optim/include/misc/optim_options.hpp to
        #include <[your eigen header library location here, should start with eigen[version number here] in e.g. /usr/local/include]/Eigen/Dense>
    use header-only library, might consider finding way of using BLAS/OpenBLAS
        ideally would figure out way to install library from headers to reduce compile time
    without intefering with access of BLAS/LAPACK by CGp by pre-compiling for additional performance boost

optim
    git clone git@github.com:kthohr/optim.git
    change line 
    change line 99 of optim/src/unconstrained/de.cpp to 
        X_next.row(i) = OPTIM_MATOPS_TRANSPOSE( par_initial_lb + OPTIM_MATOPS_HADAMARD_PROD( par_initial_ub - par_iniial_lb, OPTIM_MATOPS_RANDU_VEC(n_vals) ) );
    ./configure --head-only-version

nlohmann/json
    cd DEPENDENCY_DIR
    git clone git@github.com:nlohmann/json.git


11/11/21
  exception handling. if GP or global optimizations fail, need to just sample uniform sample with 
  logged error message
    matrix non positive definite error obtained after (10) initial samples collected
        there might be an infinite loop in the Cholesky decomposition jittering?
        in schwefel x_dim=3,4 hanging runs, matern32 length scale stuck at 1 and variance stuck (in both models) at 
            0.81832 over multiple samples
        schwefel x_dim=2 also hanging, but not on first run (completes 6 runs with decent success) 
        and doesn't have similarly "stuck" parameters on hanging run
        possible that hanging runs occur for poor condition numbers
            check to what extent they drive longer compute times
                can't find anything on this

        CURRENTLY NOT ASSIGNING OPTIMAL PARAMETERS WITH LBFGS WITH IFLAG = 0?

        what would lead to non-PD matrices, which hartmann4d (which has standardized input range) run finally led to?
            numerical error
                exacerbated by small parameter values leading to small kernel matrices?
                jitter attempts failed in hartmann4d
                    max diagonal value added is multiple of trace, in one case with hartmann4d, was 4e10
                    parameters explode on some parameter optimization runs, leads to large kernel values
                    final exploded log parameters are huge, lead to incorrect linear param values >> linear params limited internally
                    seems like we need a different optimization algorithm with bounds
                    try sklearn's FORTRAN routine instead, has bounds built in
                    seems like these issues could result with poor noise samples leading to loss surfaces where 
                    divergent parameters trivially improve loss
                    could regularize rather than use bounds? could just apply L2 to kernel variances with low weight?
                        don't really want spherical regularization, although it would prevent the observed imbalance in 
                        variances between the white kernel and the non-trivial kernel
            logical errors
            optimization sometimes explodes

        check error messages, see which matrices are breaking down
            potrf, jitter tries failed, non-PD
                with sin and quadratic funcs, kernel HPs not vanishing, 
                hartmann4d matern variance vanishing, white kernel var not vanishing
                    hartmann4d fails on first run with noise level = 0.3, maybe noise worsens issues
            symmetry error = 0 in hartmann4d

            potri also returns non-PD matrix error later, potentially implying that potrf succeeded and then potri failed
            additional LFBGS errors in MCSTEP search found, none sounds fatal, just numerical stuff
        also try different kernels in CGp, might be issue with matern32 specifically
            unlikely, but should still try
        check if I'm directly assigning CMatrix vals arrays assuming row-major order while they actually have column-major order
        error in relative error calculation, some cases observed (in deleted file) where max found = 1.4, BO opt = <~1.4 and
            rel err = -12

                check covariance matrices, other matrices that are being Cholesky decomposed
            which matrices are being decomposed specifically?
            check values of matrices, might be the case that matrices are collapsing when matern32 length scale/variance
            grows too small, which happened in some of the cases but not all
            check that symmetry is being asserted
                is being asserted, but not numerically checked, now being numerically checked
            check condition numbers
                different condition numbers, not sure at this point
        try increasing alpha/CNoise model values to improve conditioning numbers? try forcefully preventing non-PD errors
        can also try fixing a minimum value for the main kernel variances
        check whether test functions are non-isometric, i.e., whether the intrinsic length scale varies directionally
        check where exactly CNoise values came into play
        try standardizing schwefel x domain? hartmann4d is standardized, also hangs
        
        handle every GPc ndl/optim error dependent on matrices being e.g. PD, nicely behaved, everything that can go wrong stochastically, 
            likely with a random sample
        catch every other error with a random sample

        
        DONE confirm sklearn comparison tests are still similarly passing and that I didn't break something
            kernel tests passing
            GPR tests passing to same degree they were before as far as I can remember (some failures, but still optimizing, seems more like some kind of disalignment of values)
        DONE try to get these failures to occur for 1D test functions
            broke for schwefel 1D... never happened before...
            quadratic also just failed after ~65 runs, no error message, just exited, later failed with error message
        DONE try to reproduce these failures in the debugger? tricky, can't break into catch statements, could set conditional 
        breakpoints
            seeding appears to produce reproducibility as of 11/26/21
  
find solid unit testing framework, look into what Elemem
is using

implement discrete location selection


11/9/21

Select kernel with CV once we have data
in what way are the collected samples biased by the search produced by the selected kernel?

How is prior variance selected? Just observation noise?

Extensions:
prior sample weighting/weighted GP - simple technique
how to determine the weights?
if you had multiple prior subjects, you could directly compute this with leave-one-patient-out cross validation
on the log-likelihood, i.e., fit on all subjects' data but one and all of that one
patient's data but one session. Tune the weight on performance (marginal likelihood, MSE...)
this would give an optimized weight for each subject tuned for generalization performance,
could take mean or probably better, median

could look at distribution of kernel HPs across subjects, maybe just reuse HPs from previous subjects
might think that different subjects would have similar HPs, but task, classifiers, electrodes, patients, etc.
are very noisy...

could anneal prior data weighting over the course of training

question of generalization:
tuning HPs on marginal log-likelihood alone for all current data could overfit, can overfit to noise
since we're just using GP as a proxy for search, we don't necessarily care as much during search
poor generalization during search would be expected to decrease sample efficiency (which we don't want, but
wouldn't be fatal) but adding noise to the search isn't terrible given the model assumptions aren't entirely 
correct.
Weighting initial samples with prior data would provide for regularization.
Increasing the sample noise estimate would as well.
We could penalize the log likelihood in other ways as well
>> it'd really be nice to have an autograd system in place >> could consider pytorch/tensorflow c++...


We want a robust method for comparing effects of stim. after fitting
CV via fitting HPs on different subsets of subject data? how to aggregate model predictions across folds
to obtain prediction of best set of parameters?



use non-behavioral data to estimate effects on classifier features, then use mean feature weights in each 
region to estimate delta variance
start out looking at feature variances rather than classifier weights

look at all data sets with BlackRock systems and 500 ms stim length
non-behavioral data sets: ps1, 2, 2b, 3, 4 data sites - 150 patients, subjects have to sit and do little
behavioral datasets: FR3 catFR3, PAL3 - 50 patients
    stim occurs at particular points in time during a task with a particular structure
    get an effect of not only stim but also current brain activity/behavior > behavior adds noise
    but behavioral task allows for directly measuring what we care about

Mike would start with OPS data, has larger data set per patient, get pipeline working, then expand to other
data sets
OPS is most recent, if there are issues I can talk to Ryan who wrote the code, OPS is smaller though

eventually, look at aggregate classifier across subjects/regions
John Burke's univariate analyses didn't take into account feature correlations, this would allow for 
feature correlations and be on a much larger dataset (450 subjects vs. 90)




variable length scales over domain

multidimensional:
    anisotropic kernels/length scales

    discrete models (might be better to just implement a bandit model to choose sampling for a set of GPs than
        to directly use a GP with discrete RVs in combination with continuous RVs)


11/8/21

BO is mostly working on 1D test function of sin(x) with Matern32 kernel based on qualitative plotting tests
0.3 noise level in samples, lower alpha value (0.05) was used for most experiments than in sklearn
using 0.45 (value used in sklearn), resulted in flat predicted variances and less exploration
no, CGP WAS NEVER IMPLEMENTING OBSERVATION NOISE...

DE is optimizing EI decently well, misses sporadically

overall exploration is more "reluctant", much higher exploration biases being used...

CGp GP fit is much rougher than fit with sklearn using same kernel

Seems like the predicted variance might be flatter than sklearn?
sklearn appears to be only adding observation noise to sample variances, whereas CGp is adding noise to all 
elements of covariance
CGp was not adding observation noise to diagonal elements

Also had one instance where GP fit was drastically off after a new sample (curves fit to twice the true curves), 
will need to detect that... maybe just an outlier detection scheme on the log likelihood

EI returning constant values oftentimes?


Model definitely slows down considerably after 100 points, gets to about 2 Hz rate around 200 samples...
Probably will need sparse sampling, batched updates, some additional optimization/caching 
(fit HPs with only prior data from other patients), 
using better (parallelized) libraries
column-row addition update to Cholesky - Linpack - O(k^2)
averaging multiple samples together would reduce sample noise and computational costs
check if optim allows for batch sampling of the objective with population-based methods

full updates to Cholesky decomposition could be performed periodically to manage numerical error and
to remove e.g. samples from prior subjects below some weighting threshold during prior data annealing
